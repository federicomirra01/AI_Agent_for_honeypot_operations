from configuration import state
from prompts import graph_and_exploitation_inference_prompt
from .node_utils import OPEN_AI_KEY
from openai import BadRequestError 
import logging
from pydantic import BaseModel
import instructor
from openai import OpenAI
import hashlib
# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StructuredOutput(BaseModel):
    reasoning: str
    inferred_attack_graph: dict
    honeypot_exploitation: list

def get_last_epoch_fields(last_epoch):
    last_exploitation = {}
    last_attack_graph = {}
    if last_epoch:
        last_epoch = last_epoch[0].value
        last_exploitation = last_epoch.get('honeypots_exploitation', {})
        last_attack_graph = last_epoch.get('inferred_attack_graph', {})

    return last_exploitation, last_attack_graph

def compute_edge_id(edges):
    for edge in edges:
        src = edge.get("from")
        dst = edge.get("to")

        if edge.get("edge_id") and len(edge.get("edge_id")) < 32:
            m = hashlib.sha256()
            m.update(f"{src} -> {dst}".encode())
            hash = m.hexdigest()
            logger.info(f"Hash Computed: {hash}")
            
            edge["edge_id"] = hash[:32]
    return edges

async def graph_and_exploitation_inference(state: state.HoneypotStateReact, config):
    """
    Infers/Update the attack graph from event summaries
    """
    logger.info("Inference Agent")
    episodic_memory = config.get("configurable", {}).get("store")
    model_config = config.get("configurable", {}).get("model_config", "large:4.1")
    epoch_num = config.get("configurable", {}).get("epoch_num")
    last_epoch = episodic_memory.get_recent_iterations(limit=1)
    last_exploitation, last_attack_graph = get_last_epoch_fields(last_epoch)
    prompt = graph_and_exploitation_inference_prompt.INFERENCE_AND_EXPLOITATION_PROMPT.substitute(
        security_events_summary=state.security_events_summary,
        available_honeypots=state.honeypot_config,
        previous_exploitation=last_exploitation,
        previous_attack_graph=last_attack_graph,
        current_epoch=epoch_num
        ) 
    message = ""
    size, version = model_config.split(':')
    model_name = f"gpt-{version}"
    logger.info(f"Using: {model_name}")
    try:
        
        messages = {"role": "system", "content": prompt}
        agent = instructor.from_openai(OpenAI(api_key=OPEN_AI_KEY))
        response = agent.chat.completions.create(
            model=model_name,
            response_model=StructuredOutput,
            messages=[messages]
        )

        inferred_attack_graph = response.inferred_attack_graph or {}
        edges = inferred_attack_graph.get("edges", [])
        inferred_attack_graph["edges"] = compute_edge_id(edges)
        message += f"Reasoning: {str(response.reasoning)}" + "\n"
        message += f"Inferred Attack Graph: {str(response.inferred_attack_graph)}" + "\n"
        message += f"Honeypot Exploitation: {str(response.honeypot_exploitation)}"
        
        return {
            "messages": [message],
            "inferred_attack_graph":response.inferred_attack_graph, 
            "reasoning_inference":response.reasoning, 
            "honeypots_exploitation":response.honeypot_exploitation
        }
    except BadRequestError as e:
        logger.error(f"Error: {e}")
    except Exception as e:
        logger.error(f"Error parsing json in attack graph inference:\n{e}")
    return {
        "messages":[message]
        }


