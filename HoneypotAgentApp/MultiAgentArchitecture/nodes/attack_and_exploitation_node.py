import state
from prompts import inference_and_exploitation_prompt
from .node_utils import llm
import json
from openai import BadRequestError 
import logging
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def attack_graph_inference(state: state.HoneypotStateReact):
    """
    Infers/Update the attack graph from event summaries
    """
    logger.info("Inference Agent")
       
    prompt = inference_and_exploitation_prompt.INFERENCE_AND_EXPLOITATION_PROMPT.format(
        security_events_summary=state.security_events_summary,
        available_honeypots=state.honeypot_config,
        memory_context=state.memory_context
        ) 
    
    try:
        response = await llm.ainvoke(prompt)
        content = response.content
        substring = content.split("Reasoning:")
        substring = substring[1] if len(substring) > 1 else substring
        reasoning, substring1 = substring.split("Attack Graph:")
        inferred_attack_graph, honeypot_exploitation = substring1.split("Honeypots exploitation:")
        inferred_attack_graph = json.loads(inferred_attack_graph)
        honeypot_exploitation = json.loads(honeypot_exploitation)
        return {
            "messages": state.messages + [response],
            "inferred_attack_graph":inferred_attack_graph, 
            "reasoning_inference":reasoning, 
            "honeypots_exploitation":honeypot_exploitation
            }
    except BadRequestError as e:
        logger.error(f"Error: {e}")
    except Exception as e:
        logger.error(f"Error parsing json in attack graph inference:\n{e}")
    return {
        "messages":state.messages + [response],
        "inferred_attack_graph":f"Inferred graph\n{response.content}",
        }

