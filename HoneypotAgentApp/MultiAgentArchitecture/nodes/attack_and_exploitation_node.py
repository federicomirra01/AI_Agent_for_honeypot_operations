import state
from prompts import inference_and_exploitation_prompt
from .node_utils import OPEN_AI_KEY
from openai import BadRequestError 
import logging
from pydantic import BaseModel
import instructor
from openai import OpenAI

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StructuredOutput(BaseModel):
    reasoning: str
    inferred_attack_graph: dict
    honeypot_exploitation: dict

async def attack_graph_inference(state: state.HoneypotStateReact):
    """
    Infers/Update the attack graph from event summaries
    """
    logger.info("Inference Agent")
       
    prompt = inference_and_exploitation_prompt.INFERENCE_AND_EXPLOITATION_PROMPT.substitute(
        security_events_summary=state.security_events_summary,
        available_honeypots=state.honeypot_config,
        memory_context=state.memory_context
        ) 
    
    try:
        
        messages = {"role": "system", "content": prompt}
        agent = instructor.from_openai(OpenAI(api_key=OPEN_AI_KEY))
        response = agent.chat.completions.create(
            model='gpt-4.1',
            response_model=StructuredOutput,
            messages=[messages]
        )

        message = ""
        message += str(response.reasoning) + "\n"
        message += str(response.inferred_attack_graph) + "\n"
        message += str(response.honeypot_exploitation)
        
        return {
            "messages": state.messages + [message],
            "inferred_attack_graph":response.inferred_attack_graph, 
            "reasoning_inference":response.reasoning, 
            "honeypots_exploitation":response.honeypot_exploitation
        }
    except BadRequestError as e:
        logger.error(f"Error: {e}")
    except Exception as e:
        logger.error(f"Error parsing json in attack graph inference:\n{e}")
    return {
        "messages":state.messages + [message],
        }

